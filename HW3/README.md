# HW 3 (team):  Evaluating Requirements Assignment

- [ ] Give a dataflow diagram showing a `high-level architecture` of your system (approx 1 page)

- [ ] Give a dataflow diagram showing an `alternate high-level architecture` of your system; this alternate architecture should have a **different architectural style** than your first architecture (approx 1 page)

---

- [ ] Identify the **key quality attributes** for your system and assess how well each of the two architectures supports each quality attribute; the quality attributes should be selected from the list that I discussed in my first lecture (approx 1 page)

- **Reliability**: Will it perform properly under assumed conditions?
- **Efficiency**: Can the system respond quickly, do a lot of work per unit time, and scale to high loads?
- **Integrity**(Security): Is it possible to put the system into a bad state?
- **Usability**: Can real users complete their goals with the system?
- **Maintainability**: How hard will it be to make anticipated changes?
- **Testability**: Can you (semi-)automa.cally test if the system is right?
- **Flexibility**: How easily can the system adapt to unusual conditions?
- **Portability**: Could you get the system to run on a new platform
- **Reusability**: What parts of the system could you use in a new system?
- **Interoperability**: Can the system talk to other relevant systems?

---

- [ ] Identify **two failure modes**; for each mode, draw a fault tree and explain which of your two architectures is probably more prone to failure (and why)(approx 2 pages)


---

- [ ] Based on the quality and failure assessment, select one of your two architectures for further decomposition. Identify **two important elements** in your selected architecture, and for each element, give a **lower-level dataflow diagram** (approx 2 pages)


---

- [ ] **Validate** your selected architecture: **walk through the use cases** (from HW2) and succinctly describe **how the architecture supports each use case** (approx 1 page)

---

- [ ] Explain the **implications**: how would you revise your selected architecture based on the results of the validation and verification? And how would this impact the quality attributes and potential for failure? (approx 1 page)

---

- [ ] Briefly summarize the contribution of each of your team members.

- Deadline: `May 5 at 11:59pm`

***

## Schedule

### 4.29 (Mon.)



### 4.30 (Tue.)

- two team members each create a `dataflow diagram` showing a `high-level architecture`.
- They email these two "candidate" architectures to the entire team

### 5.1 (Wed.)

- two team members meet to identify **quality attributes**. They then evaluate the
- candidate architectures and write up the results, which they email to the entire team

- two other team members meet to identify **failure modes**. They
- evaluate the candidate architectures and write up the results, which they email to the entire team.

### 5.2 (Thu.)

- two team members meet to **choose an architecture for decomposition**. 
- They each decompose one architectural element. They email results to the entire team

### 5.3 (Fri.)

- two team members meet to **validate** how well the architecture supports the use cases. 
- They write up and email results.

- two other team members meet to **verify** the architecture's conformance to design principles. 
- They write up and email results.


### 5.4 (Sat.)



### 5.5 (Sun.)


***





***


